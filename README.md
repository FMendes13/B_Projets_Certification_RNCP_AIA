# RNCP38777 - Architecte en Intelligence Artificielle

Bienvenue dans mon d√©p√¥t d√©di√© √† ma formation **RNCP38777** en **Data Science** et **Data Engineering** chez **Jedha Bootcamp**. Ce d√©p√¥t est organis√© en plusieurs blocs, chacun correspondant √† un aspect cl√© de la gestion et de l'exploitation des donn√©es pour l'intelligence artificielle (IA).

## Structure du d√©p√¥t

Le d√©p√¥t est divis√© en **4 blocs principaux**, chacun contenant des dossiers et des projets li√©s √† un domaine sp√©cifique de la data et de l'IA.

### üìÇ **Bloc 1 - Concevoir et piloter la gouvernance des donn√©es**
Ce bloc traite de la gestion des donn√©es, de leur qualit√©, de leur s√©curit√© et de leur conformit√©. Vous y trouverez des projets et des ressources sur :
- La d√©finition des politiques de gouvernance des donn√©es.
- La mise en place de cadres de gestion de la qualit√© des donn√©es.
- La conformit√© aux r√©glementations (RGPD, etc.).

### üìÇ **Bloc 2 - Concevoir et d√©ployer des architectures de donn√©es (pour l'IA)**
Ce bloc se concentre sur la conception et le d√©ploiement d'architectures de donn√©es adapt√©es aux besoins de l'IA. Les projets incluent :
- La mod√©lisation de bases de donn√©es relationnelles et non relationnelles.
- L'utilisation de solutions cloud (AWS, GCP, Azure) pour le stockage et le traitement des donn√©es.
- L'int√©gration de donn√©es pour l'IA (data lakes, data warehouses).

### üìÇ **Bloc 3 - Concevoir et mettre en ≈ìuvre des pipelines de donn√©es (pour l'IA)**
Ce bloc aborde la cr√©ation de pipelines de donn√©es pour l'IA, avec un focus sur :
- L'automatisation des flux de donn√©es avec des outils comme **Apache Airflow**.
- Le traitement de donn√©es en temps r√©el avec **Apache Kafka** ou **Spark Streaming**.
- L'int√©gration de donn√©es provenant de sources vari√©es (APIs, bases de donn√©es, fichiers).

### üìÇ **Bloc 4 - Construire, d√©ployer et piloter des solutions d'IA**
Ce bloc est d√©di√© √† la construction et au d√©ploiement de mod√®les d'IA. Vous y trouverez des projets sur :
- Le d√©veloppement de mod√®les de Machine Learning avec **Scikit-learn**, **TensorFlow** ou **PyTorch**.
- Le d√©ploiement de mod√®les avec **FastAPI**, **Streamlit** ou **Docker**.
- Le monitoring et l'optimisation des mod√®les en production.

---

## Comp√©tences acquises

√Ä travers ces blocs, je d√©veloppe des comp√©tences techniques et op√©rationnelles dans les domaines suivants :
- **Langages de programmation** : Python, SQL
- **Outils de Data Engineering** : Apache Airflow, Snowflake
- **Cloud** : AWS (S3)
- **Machine Learning** : Scikit-learn
- **D√©ploiement** : Docker, Kubernetes, Streamlit


## Comment naviguer dans ce d√©p√¥t

- Chaque bloc contient un dossier d√©di√© avec des sous-dossiers pour les projets et les ressources.

---

## Contact

Si vous avez des questions ou des suggestions, n'h√©sitez pas √† me contacter :
- **Email** : frederic.mendes.semedo@gmail.com
- **LinkedIn** : [Mon Profil LinkedIn](https://www.linkedin.com/in/votre-profil-linkedin)

